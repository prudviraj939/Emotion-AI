{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "practice_emotionAIFull.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPtQQMuJ9QRbLTN4MbSuU6z",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prudviraj939/Emotion-AI/blob/main/practice_emotionAIFull.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "O9DQbjBHyCeE",
        "outputId": "72ae4006-25ee-4a89-b014-fd4af382756d"
      },
      "source": [
        "from google.colab import  drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d7227f9cdd9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m  \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    111\u001b[0m       \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m       \u001b[0muse_metadata_server\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_metadata_server\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m       ephemeral=ephemeral)\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server, ephemeral)\u001b[0m\n\u001b[1;32m    134\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     _message.blocking_request(\n\u001b[0;32m--> 136\u001b[0;31m         'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mmountpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    173\u001b[0m   request_id = send_request(\n\u001b[1;32m    174\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--> 175\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6izrlQnzqhz"
      },
      "source": [
        " %cd /content/drive/My Drive/Colab Notebooks/Modern AI Portfolio Builder/Emotion AI /  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEzBB7ALzvOA"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "from PIL import *\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "from IPython.display import display\n",
        "from tensorflow.python.keras import *\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, optimizers\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras import backend as K\n",
        "from keras import optimizers\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80b51sfqz8pP"
      },
      "source": [
        "keyfacial_df = pd.read_csv('data.csv')\n",
        "keyfacial_df['Image'] = keyfacial_df['Image'].apply(lambda x: np.fromstring(x, dtype=int, sep=' ').reshape(96,96))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsO5lWYG0HBp"
      },
      "source": [
        "import copy\n",
        "keyfacial_df_copy = copy.copy(keyfacial_df)\n",
        "columns = keyfacial_df_copy.columns[:-1]\n",
        "# Horizontal Flip - flip the images along y axis\n",
        "keyfacial_df_copy['Image'] = keyfacial_df_copy['Image'].apply(lambda x: np.flip(x, axis = 1))\n",
        "\n",
        "# since we are flipping horizontally, y coordinate values would be the same\n",
        "# Only x coordiante values would change, all we have to do is to subtract our initial x-coordinate values from width of the image(96)\n",
        "for i in range(len(columns)):\n",
        "  if i%2 == 0:\n",
        "    keyfacial_df_copy[columns[i]] = keyfacial_df_copy[columns[i]].apply(lambda x: 96. - float(x) )\n",
        "augmented_df = np.concatenate((keyfacial_df, keyfacial_df_copy))\n",
        "#increaase brightness\n",
        "import random\n",
        "keyfacial_df_copy = copy.copy(keyfacial_df)\n",
        "keyfacial_df_copy['Image'] = keyfacial_df_copy['Image'].apply(lambda x:np.clip(random.uniform(1.5, 2)* x, 0.0, 255.0))\n",
        "augmented_df = np.concatenate((augmented_df, keyfacial_df_copy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpNLJ_osHekD"
      },
      "source": [
        "# Obtain the value of images which is present in the 31st column (since index start from 0, we refer to 31st column by 30)\n",
        "img = augmented_df[:,30]\n",
        "\n",
        "# Normalize the images\n",
        "img = img/255.\n",
        "\n",
        "# Create an empty array of shape (x, 96, 96, 1) to feed the model\n",
        "X = np.empty((len(img), 96, 96, 1))\n",
        "\n",
        "# Iterate through the img list and add image values to the empty array after expanding it's dimension from (96, 96) to (96, 96, 1)\n",
        "for i in range(len(img)):\n",
        "  X[i,] = np.expand_dims(img[i], axis = 2)\n",
        "\n",
        "# Convert the array type to float32\n",
        "X = np.asarray(X).astype(np.float32)\n",
        "\n",
        "# Obtain the value of x & y coordinates which are to used as target.\n",
        "y = augmented_df[:,:30]\n",
        "y = np.asarray(y).astype(np.float32)\n",
        "\n",
        "# Split the data into train and test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPeKDPxSfGgl"
      },
      "source": [
        "def res_block(X, filter, stage):\n",
        "\n",
        "  # Convolutional_block\n",
        "  X_copy = X\n",
        "\n",
        "  f1 , f2, f3 = filter\n",
        "\n",
        "  # Main Path\n",
        "  X = Conv2D(f1, (1,1),strides = (1,1), name ='res_'+str(stage)+'_conv_a', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
        "  X = MaxPool2D((2,2))(X)\n",
        "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_a')(X)\n",
        "  X = Activation('relu')(X) \n",
        "\n",
        "  X = Conv2D(f2, kernel_size = (3,3), strides =(1,1), padding = 'same', name ='res_'+str(stage)+'_conv_b', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
        "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_b')(X)\n",
        "  X = Activation('relu')(X) \n",
        "\n",
        "  X = Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_conv_c', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
        "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_c')(X)\n",
        "\n",
        "\n",
        "  # Short path\n",
        "  X_copy = Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_conv_copy', kernel_initializer= glorot_uniform(seed = 0))(X_copy)\n",
        "  X_copy = MaxPool2D((2,2))(X_copy)\n",
        "  X_copy = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_copy')(X_copy)\n",
        "\n",
        "  # ADD\n",
        "  X = Add()([X,X_copy])\n",
        "  X = Activation('relu')(X)\n",
        "\n",
        "  # Identity Block 1\n",
        "  X_copy = X\n",
        "\n",
        "\n",
        "  # Main Path\n",
        "  X = Conv2D(f1, (1,1),strides = (1,1), name ='res_'+str(stage)+'_identity_1_a', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
        "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_1_a')(X)\n",
        "  X = Activation('relu')(X) \n",
        "\n",
        "  X = Conv2D(f2, kernel_size = (3,3), strides =(1,1), padding = 'same', name ='res_'+str(stage)+'_identity_1_b', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
        "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_1_b')(X)\n",
        "  X = Activation('relu')(X) \n",
        "\n",
        "  X = Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_identity_1_c', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
        "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_1_c')(X)\n",
        "\n",
        "  # ADD\n",
        "  X = Add()([X,X_copy])\n",
        "  X = Activation('relu')(X)\n",
        "\n",
        "  # Identity Block 2\n",
        "  X_copy = X\n",
        "\n",
        "\n",
        "  # Main Path\n",
        "  X = Conv2D(f1, (1,1),strides = (1,1), name ='res_'+str(stage)+'_identity_2_a', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
        "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_2_a')(X)\n",
        "  X = Activation('relu')(X) \n",
        "\n",
        "  X = Conv2D(f2, kernel_size = (3,3), strides =(1,1), padding = 'same', name ='res_'+str(stage)+'_identity_2_b', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
        "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_2_b')(X)\n",
        "  X = Activation('relu')(X) \n",
        "\n",
        "  X = Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_identity_2_c', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
        "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_2_c')(X)\n",
        "\n",
        "  # ADD\n",
        "  X = Add()([X,X_copy])\n",
        "  X = Activation('relu')(X)\n",
        "\n",
        "  return X\n",
        "\n",
        "\n",
        "input_shape = (96, 96, 1)\n",
        "\n",
        "# Input tensor shape\n",
        "X_input = Input(input_shape)\n",
        "\n",
        "# Zero-padding\n",
        "X = ZeroPadding2D((3,3))(X_input)\n",
        "\n",
        "# 1 - stage\n",
        "X = Conv2D(64, (7,7), strides= (2,2), name = 'conv1', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
        "X = BatchNormalization(axis =3, name = 'bn_conv1')(X)\n",
        "X = Activation('relu')(X)\n",
        "X = MaxPooling2D((3,3), strides= (2,2))(X)\n",
        "\n",
        "# 2 - stage\n",
        "X = res_block(X, filter= [64,64,256], stage= 2)\n",
        "\n",
        "# 3 - stage\n",
        "X = res_block(X, filter= [128,128,512], stage= 3)\n",
        "\n",
        "\n",
        "# Average Pooling\n",
        "X = AveragePooling2D((2,2), name = 'Averagea_Pooling')(X)\n",
        "\n",
        "# Final layer\n",
        "X = Flatten()(X)\n",
        "X = Dense(4096, activation = 'relu')(X)\n",
        "X = Dropout(0.2)(X)\n",
        "X = Dense(2048, activation = 'relu')(X)\n",
        "X = Dropout(0.1)(X)\n",
        "X = Dense(30, activation = 'relu')(X)\n",
        "\n",
        "\n",
        "model_1_facialKeyPoints = Model( inputs= X_input, outputs = X)\n",
        "model_1_facialKeyPoints.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYrD9ui3fYpS"
      },
      "source": [
        "adam = tf.keras.optimizers.Adam(learning_rate = 0.0001, beta_1 = 0.9, beta_2 = 0.999, amsgrad = False)\n",
        "model_1_facialKeyPoints.compile(loss = \"mean_squared_error\", optimizer = adam , metrics = ['accuracy'])\n",
        "\n",
        "# save the best model with least validation loss\n",
        "checkpointer = ModelCheckpoint(filepath = \"FacialKeyPoints_weights.hdf5\", verbose = 1, save_best_only = True)\n",
        "history = model_1_facialKeyPoints.fit(X_train, y_train, batch_size = 32, epochs = 2, validation_split = 0.05, callbacks=[checkpointer])\n",
        "\n",
        "#saving model\n",
        "model_json = model_1_facialKeyPoints.to_json()\n",
        "with open(\"FacialKeyPoints-model.json\",\"w\") as json_file:\n",
        "  json_file.write(model_json)\n",
        "\n",
        "#plotting train and val loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train_loss','val_loss'], loc = 'upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ub_puiILIWsd"
      },
      "source": [
        "with open('detection.json', 'r') as json_file:\n",
        "    json_savedModel= json_file.read()\n",
        "    \n",
        "# load the model architecture \n",
        "model_1_facialKeyPoints = tf.keras.models.model_from_json(json_savedModel)\n",
        "model_1_facialKeyPoints.load_weights('weights_keypoint.hdf5')\n",
        "adam = tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "model_1_facialKeyPoints.compile(loss=\"mean_squared_error\", optimizer= adam , metrics = ['accuracy'])\n",
        "\n",
        "result = model_1_facialKeyPoints.evaluate(X_test, y_test)\n",
        "print(\"Accuracy : {}\".format(result[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uodsqpUPgkJV"
      },
      "source": [
        "**Facial** **emotion** **detection**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMVqTlYug767"
      },
      "source": [
        "# read the csv files for the facial expression data\n",
        "facialexpression_df = pd.read_csv('icml_face_data.csv')\n",
        "\n",
        "def string2array(x):\n",
        "  return np.array(x.split(' ')).reshape(48, 48, 1).astype('float32')\n",
        "\n",
        "# Resize images from (48, 48) to (96, 96)\n",
        "def resize(x):\n",
        "  img = x.reshape(48, 48)\n",
        "  return cv2.resize(img, dsize=(96, 96), interpolation = cv2.INTER_CUBIC)\n",
        "\n",
        "facialexpression_df[' pixels'] = facialexpression_df[' pixels'].apply(lambda x: string2array(x))\n",
        "facialexpression_df[' pixels'] = facialexpression_df[' pixels'].apply(lambda x: resize(x))\n",
        "\n",
        "label_to_text = {0:'anger', 1:'disgust', 2:'sad', 3:'happiness', 4: 'surprise'}\n",
        "\n",
        "#visualize one from each emotion\n",
        "emotions = [0, 1, 2, 3, 4]\n",
        "for i in emotions:\n",
        "  data = facialexpression_df[facialexpression_df['emotion'] == i][:1]\n",
        "  img = data[' pixels'].item()\n",
        "  img = img.reshape(96, 96)\n",
        "  plt.figure()\n",
        "  plt.title(label_to_text[i])\n",
        "  plt.imshow(img, cmap = 'gray')\n",
        "\n",
        "#printing barplot\n",
        "facialexpression_df.emotion.value_counts().index\n",
        "facialexpression_df.emotion.value_counts()\n",
        "plt.figure(figsize = (10,10))\n",
        "sns.barplot(x = facialexpression_df.emotion.value_counts().index, y = facialexpression_df.emotion.value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgkFNLe_h2Q1"
      },
      "source": [
        "# split the dataframe in to features and labels\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "X = facialexpression_df[' pixels']\n",
        "y = to_categorical(facialexpression_df['emotion'])\n",
        "\n",
        "#reshaping image\n",
        "X = np.stack(X, axis = 0)\n",
        "X = X.reshape(24568, 96, 96, 1)\n",
        "print(X.shape, y.shape)\n",
        "\n",
        "# split the dataframe in to train, test and validation data frames\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_Test, y_train, y_Test = train_test_split(X, y, test_size = 0.1, shuffle = True)\n",
        "X_val, X_Test, y_val, y_Test = train_test_split(X_Test, y_Test, test_size = 0.5, shuffle = True)\n",
        "\n",
        "print(X_val.shape, y_val.shape)\n",
        "print(X_Test.shape, y_Test.shape)\n",
        "print(X_train.shape, y_train.shape)\n",
        "\n",
        "# image pre-processing\n",
        "X_train = X_train/255\n",
        "X_val   = X_val /255\n",
        "X_Test  = X_Test/255\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "rotation_range = 15,\n",
        "    width_shift_range = 0.1,\n",
        "    height_shift_range = 0.1,\n",
        "    shear_range = 0.1,\n",
        "    zoom_range = 0.1,\n",
        "    horizontal_flip = True,\n",
        "    fill_mode = \"nearest\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ez2bDC8xinvm"
      },
      "source": [
        "input_shape = (96, 96, 1)\n",
        "\n",
        "# Input tensor shape\n",
        "X_input = Input(input_shape)\n",
        "\n",
        "# Zero-padding\n",
        "X = ZeroPadding2D((3, 3))(X_input)\n",
        "\n",
        "# 1 - stage\n",
        "X = Conv2D(64, (7, 7), strides= (2, 2), name = 'conv1', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
        "X = BatchNormalization(axis =3, name = 'bn_conv1')(X)\n",
        "X = Activation('relu')(X)\n",
        "X = MaxPooling2D((3, 3), strides= (2, 2))(X)\n",
        "\n",
        "# 2 - stage\n",
        "X = res_block(X, filter= [64, 64, 256], stage= 2)\n",
        "\n",
        "# 3 - stage\n",
        "X = res_block(X, filter= [128, 128, 512], stage= 3)\n",
        "\n",
        "# 4 - stage\n",
        "# X = res_block(X, filter= [256, 256, 1024], stage= 4)\n",
        "\n",
        "# Average Pooling\n",
        "X = AveragePooling2D((4, 4), name = 'Averagea_Pooling')(X)\n",
        "\n",
        "# Final layer\n",
        "X = Flatten()(X)\n",
        "X = Dense(5, activation = 'softmax', name = 'Dense_final', kernel_initializer= glorot_uniform(seed=0))(X)\n",
        "\n",
        "model_2_emotion = Model( inputs= X_input, outputs = X, name = 'Resnet18')\n",
        "\n",
        "model_2_emotion.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L06m4GbujYGq"
      },
      "source": [
        "# train the network\n",
        "model_2_emotion.compile(optimizer = \"Adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
        "\n",
        "# Recall that the first facial key points model was saved as follows: FacialKeyPoints_weights.hdf5 and FacialKeyPoints-model.json\n",
        "# using early stopping to exit training if validation loss is not decreasing even after certain epochs (patience)\n",
        "earlystopping = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 20)\n",
        "# save the best model with lower validation loss\n",
        "checkpointer = ModelCheckpoint(filepath = \"FacialExpression_weights.hdf5\", verbose = 1, save_best_only=True)\n",
        "\n",
        "history = model_2_emotion.fit(train_datagen.flow(X_train, y_train, batch_size=64),\n",
        "\tvalidation_data=(X_val, y_val), steps_per_epoch=len(X_train) // 64,\n",
        "\tepochs= 2, callbacks=[checkpointer, earlystopping])\n",
        "\n",
        "# saving the model architecture to json file for future use\n",
        "model_json = model_2_emotion.to_json()\n",
        "with open(\"FacialExpression-model.json\",\"w\") as json_file:\n",
        "  json_file.write(model_json)\n",
        "\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(accuracy))\n",
        "plt.plot(epochs, accuracy, 'bo', label='Training Accuracy')\n",
        "plt.plot(epochs, val_accuracy, 'b', label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.plot(epochs, loss, 'ro', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuZwli01jvUx"
      },
      "source": [
        "with open('emotion.json', 'r') as json_file:\n",
        "    json_savedModel= json_file.read()\n",
        "    \n",
        "# load the model architecture \n",
        "model_2_emotion = tf.keras.models.model_from_json(json_savedModel)\n",
        "model_2_emotion.load_weights('weights_emotions.hdf5')\n",
        "model_2_emotion.compile(optimizer = \"Adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
        "\n",
        "score = model_2_emotion.evaluate(X_Test, y_Test)\n",
        "print('Test Accuracy: {}'.format(score[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0YWD5SSkelR"
      },
      "source": [
        "# predicted_classes = model.predict_classes(X_test)\n",
        "predicted_classes = np.argmax(model_2_emotion.predict(X_Test), axis=-1)\n",
        "y_true = np.argmax(y_Test, axis=-1)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_true, predicted_classes)\n",
        "plt.figure(figsize = (10, 10))\n",
        "sns.heatmap(cm, annot = True, cbar = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVDq1GEAkpTy"
      },
      "source": [
        "fig, axes = plt.subplots(5,5, figsize = (24, 24))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i in np.arange(25):\n",
        "    axes[i].imshow(X_test[i].reshape(96,96), cmap = 'gray')\n",
        "    axes[i].set_title('Prediction = {}\\n True = {}'.format(label_to_text[predicted_classes[i]], label_to_text[y_true[i]]))\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.subplots_adjust(wspace = 1)  \n",
        "\n",
        "#classification report\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true, predicted_classes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouzyYF0_k3NY"
      },
      "source": [
        "def predict(X_test):\n",
        "\n",
        "  # Making prediction from the keypoint model\n",
        "  df_predict = model_1_facialKeyPoints.predict(X_test)\n",
        "\n",
        "  # Making prediction from the emotion model\n",
        "  df_emotion = np.argmax(model_2_emotion.predict(X_test), axis=-1)\n",
        "\n",
        "  # Reshaping array from (856,) to (856,1)\n",
        "  df_emotion = np.expand_dims(df_emotion, axis = 1)\n",
        "\n",
        "  # Converting the predictions into a dataframe\n",
        "  df_predict = pd.DataFrame(df_predict, columns= columns)\n",
        "\n",
        "  # Adding emotion into the predicted dataframe\n",
        "  df_predict['emotion'] = df_emotion\n",
        "\n",
        "  return df_predict\n",
        "\n",
        "df_predict = predict(X_test)\n",
        "\n",
        "# Plotting the test images and their predicted keypoints and emotions\n",
        "\n",
        "fig, axes = plt.subplots(4, 4, figsize = (24, 24))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i in range(16):\n",
        "\n",
        "    axes[i].imshow(X_test[i].squeeze(),cmap='gray')\n",
        "    axes[i].set_title('Prediction = {}'.format(label_to_text[df_predict['emotion'][i]]))\n",
        "    axes[i].axis('off')\n",
        "    for j in range(1,31,2):\n",
        "            axes[i].plot(df_predict.loc[i][j-1], df_predict.loc[i][j], 'rx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5B1IhI-XSWpg"
      },
      "source": [
        "import json\n",
        "import tensorflow.keras.backend as k\n",
        "\n",
        "def deploy(directory, model):\n",
        "  MODEL_DIR = directory\n",
        "  version = 1\n",
        "\n",
        "  export_path = os.path.join(MODEL_DIR, str(version))\n",
        "  print(\"Export path : {}\\n\".format(export_path))\n",
        "\n",
        "  if os.path.isdir(export_path):\n",
        "    print('\\nAlready saved a model, cleaning up\\n')\n",
        "    !rm -r {export_path}\n",
        "\n",
        "  tf.saved_model.save(model, export_path)\n",
        "  os.environ['MODEL_DIR'] = MODEL_DIR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrrLW5bjckdA"
      },
      "source": [
        "# Let's add tensorflow-model-server package to our list of packages \n",
        "!echo \"deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
        "curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add -\n",
        "!apt update\n",
        "\n",
        "# Let's install tensorflow model server\n",
        "!apt-get install tensorflow-model-server"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jd58LcJZfSyZ"
      },
      "source": [
        "deploy('/model', model_1_facialKeyPoints)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hebQ-ipngCnS"
      },
      "source": [
        "%%bash --bg \n",
        "nohup tensorflow_model_server \\\n",
        "  --rest_api_port=4500 \\\n",
        "  --model_name=keypoint_model \\\n",
        "  --model_base_path=\"${MODEL_DIR}\" >server.log 2>&1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E96CKYzZVHgB"
      },
      "source": [
        "!tail server.log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yI8RWptWVNqG"
      },
      "source": [
        "deploy('/model1', model_2_emotion)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qYWH4WeV5zx"
      },
      "source": [
        "%%bash --bg \n",
        "nohup tensorflow_model_server \\\n",
        "  --rest_api_port=4000 \\\n",
        "  --model_name=emotion_model \\\n",
        "  --model_base_path=\"${MODEL_DIR}\" >server.log 2>&1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90Ns2et1WCp1"
      },
      "source": [
        "!tail server.log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nml0-mZ5WGoX"
      },
      "source": [
        "import requests\n",
        "\n",
        "# Function to make predictions from deployed models\n",
        "def response(data):\n",
        "  headers = {\"content-type\": \"application/json\"}\n",
        "  json_response = requests.post('http://localhost:4500/v1/models/keypoint_model/versions/1:predict', data=data, headers=headers, verify = False)\n",
        "  df_predict = json.loads(json_response.text)['predictions']\n",
        "  json_response = requests.post('http://localhost:4000/v1/models/emotion_model/versions/1:predict', data=data, headers=headers, verify = False)\n",
        "  df_emotion = np.argmax(json.loads(json_response.text)['predictions'], axis = 1)\n",
        "  \n",
        "  # Reshaping array from (856,) to (856,1)\n",
        "  df_emotion = np.expand_dims(df_emotion, axis = 1)\n",
        "\n",
        "  # Converting the predictions into a dataframe\n",
        "  df_predict= pd.DataFrame(df_predict, columns = columns)\n",
        "\n",
        "  # Adding emotion into the predicted dataframe\n",
        "  df_predict['emotion'] = df_emotion\n",
        "\n",
        "  return df_predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkKhJD6_ac9W"
      },
      "source": [
        "df_predict = response(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-Wu1hZT7oWY"
      },
      "source": [
        "fig, axes = plt.subplots(3, 1, figsize = (24, 24))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i in range(3):\n",
        "\n",
        "    axes[i].imshow(X_test[i].squeeze(),cmap='gray')\n",
        "    axes[i].set_title('Prediction = {}'.format(label_to_text[df_predict['emotion'][i]]))\n",
        "    axes[i].axis('off')\n",
        "    for j in range(1,31,2):\n",
        "            axes[i].plot(df_predict.loc[i][j-1], df_predict.loc[i][j], 'rx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sG2FecJi7tKz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}